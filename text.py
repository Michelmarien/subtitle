import torch

def check_gpu_availability():
    """V√©rifie si CUDA est disponible"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"‚úÖ GPU d√©tect√© : {gpu_name}")
        print(f"üíæ M√©moire GPU : {gpu_memory:.2f} GB")
        return True
    else:
        print("‚ùå Pas de GPU CUDA d√©tect√©")
        print("   ‚Üí Installez PyTorch avec CUDA : https://pytorch.org/get-started/locally/")
        return False

# Test
if check_gpu_availability():
    device = 'cuda'
else:
    device = 'cpu'
